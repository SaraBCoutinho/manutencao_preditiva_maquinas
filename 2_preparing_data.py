# -*- coding: utf-8 -*-
"""Desafio_ciclo2_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1St67LsRZrNwybe0XZHbvg4dzVzzamgxP

##Preparação do ambiente
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
#--Preparação do ambiente
!pip install fancyimpute
 
# #imports
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from fancyimpute import IterativeImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer
from sklearn.linear_model import BayesianRidge
from fancyimpute import IterativeImputer as MICEImputer
from collections import Counter
from sklearn.neighbors import NearestNeighbors
 
# #--Data
from google.colab import files
uploaded = files.upload()

file = '/content/bootcamp_train_1.csv'
df = pd.read_csv(file)
df.head(2)

!mkdir 'preparing_data/'
!mkdir 'preparing_data/figures/'
path = '/content/preparing_data/figures/'

#--Análise inicial do dataset
nome = 'Falhas' #nome dataset
print("-"*50)
print(f" Dataset: {nome}")
df = df.drop(columns=['Unnamed: 0'])
print(f"Tamanho: {df.shape}")
print("\nPrimeiras linhas:")
df.info()

#--Funções
#coeficiente de variação cv = desvio / média
def calcular_cv(data):
  """Função para calcular o coeficiente de variação"""
  media = data.mean()
  desvio = data.std()
  cv = desvio / media
  return cv

def coeficiente_var(data):
  """Função para retornar a heterogeidade dos dados"""
  cv = calcular_cv(data)
  if cv < 0.1:
    return 'Heterogeneidade baixa'
  elif cv < 0.2:
    return 'Heterogeneidade média'
  elif cv < 0.3:
    return 'Heterogeneidade alta'
  else:
    return 'Heterogeneidade muito alta'

def encontrar_outliers(data):
  """Função para encontrar os outliers pelo método IQR"""
  if len(data) == 0:
      return 0
  Q1 = data.quantile(0.25)
  Q3 = data.quantile(0.75)
  IQR = Q3 - Q1
  lower_bound = Q1 - 1.5 * IQR
  upper_bound = Q3 + 1.5 * IQR
  return ((data < lower_bound) | (data > upper_bound))

def count_outliers(data):
  """Função para contar os outliers pelo método IQR"""
  return encontrar_outliers(data).sum()

def cap_outliers(df, column_names):
    """Substitui valores discrepantes por LS ou LI"""
    df_capped = df.copy()
    for column in column_names:
        Q1 = df_capped[column].quantile(0.25)
        Q3 = df_capped[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df_capped.loc[df_capped[column] < lower_bound, column] = lower_bound #li
        df_capped.loc[df_capped[column] > upper_bound, column] = upper_bound #ls
    return df_capped

def impute_outliers_multi_column(df, column_names, method, k_neighbors=5):
  """Aplica técnica de substituição de valores discrepantes em várias colunas"""
  df_imputed = df.copy()

  for column_name in column_names:
      print(f"\n--- Processando a coluna: '{column_name}' ---")
      Q1 = df_imputed[column_name].quantile(0.25)
      Q3 = df_imputed[column_name].quantile(0.75)
      IQR = Q3 - Q1
      lower_bound = Q1 - 1.5 * IQR
      upper_bound = Q3 + 1.5 * IQR
      outlier_indices = df_imputed[
          (df_imputed[column_name] < lower_bound) | (df_imputed[column_name] > upper_bound)
      ].index

      if len(outlier_indices) == 0:
          print("Nenhum valor discrepante encontrado.")
          continue

      print(f"Valores discrepantes identificados: {len(outlier_indices)}.")

      if method == 'mean':
          mean_value = df_imputed[column_name].mean()
          df_imputed.loc[outlier_indices, column_name] = mean_value
          print(f"Valores discrepantes substituídos pela Média ({mean_value:.2f}).")

      elif method == 'median':
          median_value = df_imputed[column_name].median()
          df_imputed.loc[outlier_indices, column_name] = median_value
          print(f"Valores discrepantes substituídos pela Mediana ({median_value:.2f}).")

      elif method == 'knn':
          #valores discrepantes substituidos por np.nan para serem imputados pelo KNN
          df_imputed.loc[outlier_indices, column_name] = np.nan
  if method == 'knn':
      numerical_cols = df_imputed.select_dtypes(include=np.number).columns
      imputer = KNNImputer(n_neighbors=k_neighbors)
      df_imputed[numerical_cols] = imputer.fit_transform(df_imputed[numerical_cols])
      print(f"\nImputação KNN concluída para todas as colunas.")

  return df_imputed

def calcul_imbalance_ratio(data):
  """Função para calcular IR(Imbalance Ratio)"""
  class_counts = data.value_counts()
  majority_count = class_counts.iloc[0]
  minority_count = class_counts.iloc[-1]
  imbalance_ratio = majority_count / minority_count
  print(f"Class counts:\n{class_counts}")
  print(f"Imbalance Ratio (IR): {round(imbalance_ratio,2)}")
  return imbalance_ratio

def classify_imbalance_ratio(imbalance_ratio):
  """Função para classificar IR(Imbalance Ratio)"""
  if imbalance_ratio < 3:
    return print("low IR")
  elif imbalance_ratio < 9 :
    return print("medium IR")
  else:
    return print("high IR")

#--Tratando valores ausentes
print(df.isnull().sum())
# Estatísticas básicas
print(" Estatísticas descritivas: ")
print(df[['tempA','tempP','velR','torque','desgF']].describe().T[["mean", "50%", "std"]], "\n")
# Boxplot
df[['tempA','tempP','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot Dados Originais - {nome}", figsize=(8,4))
plt.show()
plt.savefig(path+'boxplot_falhas_valores_ausentes.pdf')

print("\n Valores únicos colunas com vazios:")
columns_missing = ['tempA','tempP','velR','torque','desgF']
print(df[columns_missing].nunique(), "\n")

#análise da heterogeneidade para inputação dos dados
print("\n Heterogeneidade dos dados:")
print(f"Dados tempA possuem {coeficiente_var(df['tempA'])}")
print(f"Dados tempP possuem {coeficiente_var(df['tempP'])}")
print(f"Dados velR possuem {coeficiente_var(df['velR'])}")
print(f"Dados torque possuem {coeficiente_var(df['torque'])}")
print(f"Dados desgF possuem {coeficiente_var(df['desgF'])}")

print("-" * 50)
print("Aplicando técnicas de imputação...")
print("-" * 50)

# Criando cópias para cada técnica
df_original = df.copy()
df_mean = df.copy()
df_knn = df.copy()
df_mice = df.copy()
df_interpolate = df.copy()

# Imputação por média
imputer_mean = SimpleImputer(strategy='mean')
df_mean[columns_missing] = imputer_mean.fit_transform(df_mean[columns_missing])
# Boxplot
df_mean[['tempA','tempP','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot Imputação por Média - {nome}", figsize=(8,4))
plt.savefig(path+'boxplot_falhas_valores_ausentes_mean.pdf')

# Imputação por Interpolação (linear)
df_interpolate[columns_missing] = df_interpolate[columns_missing].interpolate(method='linear')
# Boxplot
df_interpolate[['tempA','tempP','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot Imputação por Interpolação - {nome}", figsize=(8,4))
plt.savefig(path+'boxplot_falhas_valores_ausentes_interpolate.pdf')

# Imputação KNN (KNNImputer, n=5)
imputer_knn = KNNImputer(n_neighbors=5)
df_knn[columns_missing] = imputer_knn.fit_transform(df_knn[columns_missing])
# Boxplot
df_knn[['tempA','tempP','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot Inputação por KNN - {nome}", figsize=(8,4))
plt.savefig(path+'boxplot_falhas_valores_ausentes_knn.pdf')

# Imputação MICE
imputer_mice = MICEImputer(verbose=False)
imputed_mice_data = imputer_mice.fit_transform(df_mice[columns_missing])
df_mice[columns_missing] = pd.DataFrame(imputed_mice_data, columns=columns_missing, index=df_mice.index)
# Boxplot
df_mice[['tempA','tempP','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot Inputação MICE- {nome}", figsize=(8,4))
plt.savefig(path+'boxplot_falhas_valores_ausentes_mice.pdf')

print("Imputação concluída para todas as técnicas.")
print("-" * 50)

#analisando os outliers por técnica para cada coluna
print("\nResumo da Contagem de Outliers por técnica para as características:")
print("-"*100)
total_out_original, total_out_mean, total_out_interpolate, total_out_knn, total_out_mice = 0, 0, 0, 0, 0

for col in columns_missing:
    outliers_original = count_outliers(df_original[col].dropna())
    total_out_original += outliers_original
    outliers_mean = count_outliers(df_mean[col])
    total_out_mean += outliers_mean
    outliers_interpolate = count_outliers(df_interpolate[col])
    total_out_interpolate += outliers_interpolate
    outliers_knn = count_outliers(df_knn[col])
    total_out_knn += outliers_knn
    outliers_mice = count_outliers(df_mice[col])
    total_out_mice += outliers_mice

    print(f"\nColuna '{col}':")
    print(f"  - Original (sem imputação): {outliers_original} outliers")
    print(f"  - Imputação por Média:      {outliers_mean} outliers")
    print(f"  - Imputação por Interpolação: {outliers_interpolate} outliers")
    print(f"  - Imputação KNN:            {outliers_knn} outliers")
    print(f"  - Imputação MICE:            {outliers_mice} outliers")

print("\n Total outliers por técnica:")
print(f"  - Sem imputação: {total_out_original} outliers")
print(f"  - Imputação Média: {total_out_mean} outliers")
print(f"  - Imputação Interpolação: {total_out_interpolate} outliers")
print(f"  - Imputação Knn: {total_out_knn} outliers")
print(f"  - Imputação MICE: {total_out_mice} outliers")

#substituindo os valores pelos valores calculados para as características e técnicas escolhidas
#interpolação: tempA, tempP, torque
df['tempA'], df['tempP'],df['torque'] = df_interpolate['tempA'],  df_interpolate['tempP'],  df_interpolate['torque']
#média: velR, desgF
df['velR'], df['desgF'] = df_mean['velR'], df_mean['desgF']

#revendo valores faltantes pós ajuste
print("\n Total outliers:")
print("-"*50)
print(f"  - : {total_out_original} outliers")
df.isnull().sum()
total_out_final = 0
for col in columns_missing:
    outliers = count_outliers(df[col])#.dropna()
    total_out_final += outliers
print("\n Total outliers:")
print(f"  - Pré inputação : {total_out_original} outliers")
print(f"  - Pós inputação : {total_out_final} outliers")
print(f"Acrescimo de: {total_out_final - total_out_original} outliers, mas é menor que usando apenas uma técnica e representa {round((total_out_final/total_out_original)-1,2)}% acima do conjunto original.")

#--Encoding
df_backup = df.copy()
print("Valores únicos colunas para encoding:")
print("-"*50)
#features categoricas
columns_embedding = ['id','tipo','F','FDF','FDC','FP','FAL']
columns_embedding_bool = ['FTE']
print(df[columns_embedding].nunique(), "\n")

#c1, c2, c3, c4, c5, c6 = Counter(df['tipo']), Counter(df['F']), Counter(df['FDF']), Counter(df['FDC']), Counter(df['FP']), Counter(df['FAL'])
#for c in [c1, c2, c3, c4, c5, c6]:
#  itens, frequencias = list(c.keys()), list(c.values())
#  plt.figure(figsize=(8, 6))
#  plt.bar(itens, frequencias, color='skyblue')
#  plt.xlabel('Itens', fontsize=12)
#  plt.ylabel('Frequência', fontsize=12)
#  plt.title('Histograma de Frequência de Itens', fontsize=14)
#  plt.xticks(rotation=45)
#  plt.savefig(path+'histograma_frequencia_itens_categoricos'+ str(c)+'.pdf')
#  plt.show()

# Lista de colunas
colunas_c = ['tipo', 'F', 'FDF', 'FDC', 'FP', 'FAL']
for col in colunas_c:
    c = Counter(df[col])
    itens, frequencias = list(c.keys()), list(c.values())
    plt.figure(figsize=(8, 6))
    plt.bar(itens, frequencias, color='skyblue')
    plt.xlabel('Itens', fontsize=12)
    plt.ylabel('Frequência', fontsize=12)
    plt.title(f'Histograma de Frequência de Itens- {col}', fontsize=14)
    plt.xticks(rotation=45)
    plt.show()
    plt.savefig(path + f'histograma_frequencia_itens_categoricos_{col}.pdf')

total = Counter(df['tipo']).get('L') + Counter(df['tipo']).get('M') + Counter(df['tipo']).get('H')
v1 = round(Counter(df['tipo']).get('L')/total,1)
v2 = round(Counter(df['tipo']).get('M')/total,1)
v3 = round(Counter(df['tipo']).get('H')/total,1)
dict_tipo = {'L':v1, 'M':v2, 'H':v3}
df['tipo'] = df['tipo'].map(dict_tipo)
if 'Unnamed: 0' in df.columns:
  df = df.drop(columns=['Unnamed: 0'])
#usa factorize() para obter os códigos numéricos e os valores únicos
codigos, unicos = pd.factorize(df['id'])
df['id'] = codigos
#arredondando valores desgF 1 casa decimal (deixei pra trazer uma precisao maior que 1 casa)
df['desgF'] = round(df['desgF'],1)

#ajustando as colunas de Falhas
print("-"*50)
print(f'Falhas F: {set(df['F'])}')
print(f'Falhas FDF: {set(df['FDF'])}')
print(f'Falhas FDC: {set(df['FDC'])}')
print(f'Falhas FP: {set(df['FP'])}')
print(f'Falhas FTE: {set(df['FTE'])}')
print(f'Falhas FAL: {set(df['FAL'])}')

for element in set(df['F']):
  print(element,type(element))

#tratando valores das colunas de falhas
df2_backup2 = df.copy()
df = df.copy()
#dict_falhas = {'Não': '0', 'não': '0', 'N': '0', 'nao': '0', 'False':'0', 'Sim': '1', 'sim':'1', 'y':'1', 'True':'1' }
df[['F','FDF', 'FDC', 'FP','FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('y', 1)#[df['F']=='y']
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('Sim', 1)
df[['F','FDF', 'FDC', 'FP','FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('sim', 1)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('True', 1)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('1', 1)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('N', 0)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('não', 0)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('nao', 0)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('False', 0)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('Não', 0)
df[['F','FDF', 'FDC', 'FP', 'FAL']] = df[['F','FDF', 'FDC', 'FP', 'FAL']].replace('0', 0)
df[['FTE']] = df[['FTE']].replace(False, 0)
df[['FTE']] = df[['FTE']].replace(True, 1)

#revendo ajustes aplicados
print("-"*50)
print(f'Falhas F: {set(df['F'])}')
print(f'Falhas FDF: {set(df['FDF'])}')
print(f'Falhas FDC: {set(df['FDC'])}')
print(f'Falhas FP: {set(df['FP'])}')
print(f'Falhas FTE: {set(df['FTE'])}')
print(f'Falhas FAL: {set(df['FAL'])}')

set(df[(df['FAL']=='-')]['F'])
df_extra = df[(df['FDF']=='-') | (df['FAL']=='-')] #para ser tratado posteriormente
#df[(df['FDF']!='-') | (df['FAL']!='-')].shape
#removendo dados com F = '-'
df = df[(df['FDF']!='-')]
df = df[(df['FAL']!='-')]
#shape dataframe resultante
#df.shape

#revendo ajustes aplicados
print("-"*50)
print(f'Falhas F: {set(df['F'])}')
print(f'Falhas FDF: {set(df['FDF'])}')
print(f'Falhas FDC: {set(df['FDC'])}')
print(f'Falhas FP: {set(df['FP'])}')
print(f'Falhas FTE: {set(df['FTE'])}')
print(f'Falhas FAL: {set(df['FAL'])}')
#df.shape[0]
#df_original.shape[0]
print(f"Redução de {round((1-(df.shape[0]/df_original.shape[0])),3)*100}% do dataset original com separação do outro grupo")

#--Tratando outliers
df_backup3 = df.copy()
print("-"*50)
# Boxplot
df.select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot - C/Discrepantes - {nome}", figsize=(8,4))
plt.show()
plt.savefig(path+'boxplot_falhas_antes_tratamento_discrepantes.pdf')
df[['tempA','tempP','umiR','velR','torque','desgF']].select_dtypes(include=[np.number]).plot(kind="box", title=f"Boxplot - C/Discrepantes - Variáveis - {nome}", figsize=(8,4))
plt.show()
plt.savefig(path+'boxplot_falhas_antes_tratamento_discrepantes_selecao_variaveis.pdf')

# Scatter matrix
sns.pairplot(df[['tempA','tempP','umiR','velR','torque','desgF']], diag_kind="kde", corner=True)
plt.suptitle(f"Pairplot - {nome}", y=1.02)
plt.show()
plt.savefig(path+'pairplot_falhas_antes_tratamento_discrepantes.pdf')

#amostras de 32k dados - teste Kolmogorov
from scipy import stats

for col in ['tempA', 'tempP', 'umiR', 'velR', 'torque', 'desgF']:
  dados = df[col]
  print("\n--- Teste de Kolmogorov-Smirnov (KS) ---")
  media, std_dev = np.mean(dados), np.std(dados)
  ks_stat, p_value_ks = stats.kstest(dados, 'norm', args=(media, std_dev))
  print("Conclusão do teste:", "os dados provavelmente são normais." if p_value_ks > 0.05 else "os dados provavelmente não são normais.")

# Heatmap de correlação
plt.figure(figsize=(6,4))
sns.heatmap(df[['tempA', 'tempP', 'umiR', 'velR', 'torque', 'desgF', 'F', 'FDC', 'FP', 'FTE','FAL']].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title(f"Correlação c/Discrepantes - {nome}")
plt.show()
plt.savefig(path+'heatmap_falhas_antes_tratamento_discrepantes.pdf')

qtd_outliers = count_outliers(df)
print(f" Quantidade de outliers: {qtd_outliers}\n")
print("-"*50)
outlier_stats = {"total_registros": len(df), "outliers": qtd_outliers, "proporcao_outliers": round(qtd_outliers / len(df),2)*100}
print(outlier_stats)

#outliers por coluna
for col in ['tempA','tempP', 'umiR', 'velR', 'torque', 'desgF']:
  #Q1 = df[col].quantile(0.25)
  #Q3 = df[col].quantile(0.75)
  #IQR = Q3 - Q1
  #print(f"{col}: IQR {round(IQR,2)}")
  #limite_inferior = Q1 - 1.5 * IQR
  #limite_superior = Q3 + 1.5 * IQR
  #out = ((df[col] < limite_inferior) | (df[col] > limite_superior))
  out = encontrar_outliers(df[col])
  qtd_out = out.sum()
  print(f" Quantidade de outliers: {qtd_out} e percentual do total: {round(qtd_out/df.shape[0],2)*100} %\n")

#colunas tempA, tempP, velR, desgF com > 10% dos dados sendo outliers
#df[['tempA','tempP','velR','desgF']].describe()
#coeficiente de variação
print(f"Dados tempA possuem {round(calcular_cv(df['tempA']),2)}")
print(f"Dados tempP possuem {round(calcular_cv(df['tempP']),2)}")
print(f"Dados velR possuem {round(calcular_cv(df['velR']),2)}")
print(f"Dados desgF possuem {round(calcular_cv(df['desgF']),2)}")

# Scatter matrix
sns.pairplot(df[['tempA','tempP','velR','desgF']], diag_kind="kde", corner=True)
plt.suptitle(f"Distribuição variáveis c/Discrepantes - {nome}", y=1.02)
plt.show()
plt.savefig(path+'pairplot_falhas_antes_tratamento_discrepantes_selecao_variaveis.pdf')

#tratamento outliers: mediana, knn, média, interpolação, LS_LI
columns_to_process = ['tempA','tempP','velR','desgF'] #lista de colunas a serem processadas
df_treated_knn = impute_outliers_multi_column(df, columns_to_process, method='knn', k_neighbors=3)
df_treated_median = impute_outliers_multi_column(df, columns_to_process, method='median')
df_treated_mean = impute_outliers_multi_column(df, columns_to_process, method='mean')
df_capped = cap_outliers(df, columns_to_process)


#comparando os resultados das técnicas
#verifica estatísticas para os dados substituídos por cada técnica e os originais
print("\n--original cv--")
for col in columns_to_process:
  print(f"{col}:{ round(calcular_cv(df[col]),4)}")
print("\n--knn--")
for col in columns_to_process:
  print(f"{col}:{round(calcular_cv(df_treated_knn[col]),4)}")
print("\n--median--")
for col in columns_to_process:
  print(f"{col}:{ round(calcular_cv(df_treated_median[col]),4)}")
print("\n--mean--")
for col in columns_to_process:
  print(f"{col}:{ round(calcular_cv(df_treated_mean[col]),4)}")
print("\n--capped--")
for col in columns_to_process:
  print(f"{col}:{ round(calcular_cv(df_capped[col]),4)}")

results = []
dfs_dict = {'Original': df,'Média': df_treated_mean,'Mediana': df_treated_median,'KNN': df_treated_knn,'Capped': df_capped}

for approach, current_df in dfs_dict.items():
    for col in columns_to_process:
        results.append({
            'Abordagem': approach,'CV': calcular_cv(current_df[col])
        })

results_df = pd.DataFrame(results)

fig, ax = plt.subplots(figsize=(10, 6))
fig.suptitle('Comparativo do Coeficiente de Variação (CV) por Abordagem', fontsize=16)
print("-"*50)
bar_width = 0.2
index = np.arange(len(columns_to_process))

for i, approach in enumerate(dfs_dict.keys()):
    subset = results_df[results_df['Abordagem'] == approach]
    bars = ax.bar(index + i * bar_width, subset['CV'], bar_width, label=approach)
    ax.bar_label(bars, padding=3, fmt='%.2f')

ax.set_xlabel('Variável')
ax.set_ylabel('Valor do CV')
ax.set_xticks(index + 1.5 * bar_width)
ax.set_xticklabels(columns_to_process)
ax.legend(title='Abordagem')

plt.tight_layout()
plt.show()
plt.savefig(path+'comparativo_cv_abordagens_substituicao_discrepantes.pdf')

#conjunto df e df_treated para armazenar os dados sem substituição dos valores discrepantes (df)
#e com substituição dos valores discrepantes (df_treated)
df_backup4, df_treated = df.copy(), df.copy()

for column in ['velR', 'desgF']: #colunas selecionadas para imputação
    print(f"--- Processando a coluna: '{column}' ---")
    Q1 = df_treated[column].quantile(0.25)
    Q3 = df_treated[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_treated.loc[df_treated[column] < lower_bound, column] = lower_bound #li
    df_treated.loc[df_treated[column] > upper_bound, column] = upper_bound #ls
#df.describe()
#df_treated.describe()

#visualizando quantidade de discrepantes e % do total antes e após tratamento
for df in [df,df_treated]:
  for col in ['velR','desgF']:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    #media = df[col].mean()
    print(f"{col}: IQR {round(IQR,2)}")
    limite_inferior = Q1 - 1.5 * IQR
    limite_superior = Q3 + 1.5 * IQR
    out = ((df[col] < limite_inferior) | (df[col] > limite_superior))
    qtd_out = out.sum()
    print(f" Quantidade de outliers: {qtd_out} e percentual do total: {round(qtd_out/df.shape[0],2)*100} %\n")

#--Análise de balanceamento: analisando balanceamento para próximas etapas
#métrica: Imbalance Ratio
df_backup5 = df.copy()
df_treated_backup = df_treated.copy()
imbalance_ratio = calcul_imbalance_ratio(df['F'])
resposta = classify_imbalance_ratio(imbalance_ratio)
print(resposta)

#gráfico da distribuição das labels (binário)
plt.figure(figsize=(6, 4))
class_counts = df['F'].value_counts()
class_counts.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Distribuição das Classes - 2 Classes')
plt.xlabel('Classe')
plt.ylabel('Frequência')
plt.xticks(rotation=0)
plt.show()
plt.savefig(path+'distribuicao_classes_2_classes.pdf')

#gráfico da distribuição das labels (multilabel)
#visualizando as classes
colunas_labels,df_multi = ['FDF','FDC','FP','FTE','FAL'], df.copy()
df_multi["labels"] = df[colunas_labels].apply(lambda row: list(row.values),axis=1)
class_counts = df_multi['labels'].value_counts()
print(f"Frequências das classes: {class_counts}")
plt.figure(figsize=(20, 4))
class_counts.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Frequência das Classes - Multilabel')
plt.xlabel('Classe')
plt.ylabel('Frequência')
plt.xticks(rotation=0)
plt.show()
plt.savefig(path+'distribuicao_classes_multilabel.pdf')

#salvando dados para próxima etapa
df_backup6 = df.copy()
df_treated_backup2 = df_treated.copy()
df.to_csv('bootcamp_train_2_df_2.csv')
df_treated.to_csv('bootcamp_train_2_df_treated_2.csv')

#download zip imagens
!zip -r preparing_data.zip preparing_data/
